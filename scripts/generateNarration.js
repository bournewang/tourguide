#!/usr/bin/env node

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { exec } from 'child_process';
import { createHash } from 'crypto';
import process from 'process';
import { synthesizeSpeech } from './microsoftTTS.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration
const AZURE_SPEECH_KEY = process.env.AZURE_SPEECH_KEY || '';
const AZURE_SPEECH_REGION = process.env.AZURE_SPEECH_REGION || 'eastus';
const DEFAULT_OUTPUT_FORMAT = 'audio-16khz-32kbitrate-mono-mp3';

// Voice mapping for characters
const VOICE_MAPPING = {
  'xiaoxiao': 'zh-CN-XiaoxiaoNeural',    // æ—ç™½ - å¥³å£°ï¼Œæ¸©æŸ”
  'yunxi': 'zh-CN-YunxiNeural',          // ç¥å…‰ - ç”·å£°ï¼Œæ¸©æš–
  'yunjian': 'zh-CN-YunjianNeural',      // è¾¾æ‘©/å®é™/æŠ¤æ³•ç¥ - ç”·å£°ï¼Œç¨³é‡
  'xiaoyi': 'zh-CN-XiaoyiNeural',        // å¤‡ç”¨å¥³å£°
  'xiaomo': 'zh-CN-XiaomoNeural',        // å¤‡ç”¨å¥³å£°ï¼Œæˆç†Ÿ
};

function showUsage() {
  console.log(`
ğŸ­ å°‘æ—å¯ºæ™¯ç‚¹å‰§æœ¬è¯­éŸ³ç”Ÿæˆå·¥å…·

ç”¨æ³•:
  node generateNarration.js [é€‰é¡¹] <script.json> <output_dir>

å‚æ•°:
  script.json    å‰§æœ¬JSONæ–‡ä»¶è·¯å¾„
  output_dir     è¾“å‡ºç›®å½•è·¯å¾„

é€‰é¡¹:
  -k, --key <key>         Azure Speech APIå¯†é’¥
  -g, --region <region>   AzureåŒºåŸŸ (é»˜è®¤: eastus)
  --no-combine            ä¸åˆå¹¶éŸ³é¢‘æ–‡ä»¶ï¼Œåªç”Ÿæˆå•ç‹¬çš„ç‰‡æ®µ
  --rate <rate>           è¯­é€Ÿè°ƒæ•´ (é»˜è®¤: -10%)
  --pause <seconds>       æ®µè½é—´åœé¡¿æ—¶é—´ (é»˜è®¤: 1.0ç§’)
  --help                  æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  node generateNarration.js lixueting-script.json ./audio/lixueting/
  node generateNarration.js --rate "-15%" --pause 1.5 script.json ./output/
  node generateNarration.js --no-combine script.json ./segments/

ç¯å¢ƒå˜é‡:
  SPEECH_KEY     - Azure Speech APIå¯†é’¥
  SPEECH_REGION  - AzureåŒºåŸŸ

å‰§æœ¬æ ¼å¼:
  [
    {
      "character": "æ—ç™½",
      "voice": "xiaoxiao", 
      "line": "æ–‡æœ¬å†…å®¹"
    },
    {
      "character": "éŸ³æ•ˆ",
      "voice": "sound_effect",
      "line": "éŸ³æ•ˆæè¿°"
    }
  ]

æ³¨æ„:
  - voiceä¸º"sound_effect"çš„è¡Œä¼šè¢«è·³è¿‡
  - æœ€ç»ˆä¼šç”Ÿæˆåˆå¹¶çš„å®Œæ•´éŸ³é¢‘æ–‡ä»¶
  - æ”¯æŒå¤šè§’è‰²è¯­éŸ³åˆ‡æ¢
`);
}

function parseArguments() {
  const args = process.argv.slice(2);
  const options = {
    scriptFile: null,
    outputDir: null,
    key: AZURE_SPEECH_KEY,
    region: AZURE_SPEECH_REGION,
    combine: true,
    rate: '-10%',
    pause: 1.0
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    
    switch (arg) {
      case '--help':
        showUsage();
        process.exit(0);
        break;
      case '-k':
      case '--key':
        if (i + 1 < args.length) {
          options.key = args[++i];
        }
        break;
      case '-g':
      case '--region':
        if (i + 1 < args.length) {
          options.region = args[++i];
        }
        break;
      case '--no-combine':
        options.combine = false;
        break;
      case '--rate':
        if (i + 1 < args.length) {
          options.rate = args[++i];
        }
        break;
      case '--pause':
        if (i + 1 < args.length) {
          options.pause = parseFloat(args[++i]);
        }
        break;
      default:
        if (!arg.startsWith('-')) {
          if (!options.scriptFile) {
            options.scriptFile = arg;
          } else if (!options.outputDir) {
            options.outputDir = arg;
          }
        }
        break;
    }
  }

  return options;
}

function ensureDirectoryExists(dirPath) {
  if (!fs.existsSync(dirPath)) {
    fs.mkdirSync(dirPath, { recursive: true });
    console.log(`ğŸ“ åˆ›å»ºç›®å½•: ${dirPath}`);
  }
}

function loadScript(scriptPath) {
  try {
    const scriptContent = fs.readFileSync(scriptPath, 'utf8');
    const script = JSON.parse(scriptContent);
    
    if (!Array.isArray(script)) {
      throw new Error('å‰§æœ¬æ–‡ä»¶å¿…é¡»æ˜¯JSONæ•°ç»„æ ¼å¼');
    }
    
    console.log(`ğŸ“– åŠ è½½å‰§æœ¬: ${scriptPath}`);
    console.log(`ğŸ“ å…± ${script.length} è¡Œå¯¹è¯`);
    
    return script;
  } catch (error) {
    throw new Error(`åŠ è½½å‰§æœ¬å¤±è´¥: ${error.message}`);
  }
}

function validateScript(script) {
  const requiredFields = ['character', 'voice', 'line'];
  const errors = [];
  
  script.forEach((item, index) => {
    requiredFields.forEach(field => {
      if (!item[field]) {
        errors.push(`ç¬¬ ${index + 1} è¡Œç¼ºå°‘å­—æ®µ: ${field}`);
      }
    });
    
    if (item.voice && item.voice !== 'sound_effect' && !VOICE_MAPPING[item.voice]) {
      errors.push(`ç¬¬ ${index + 1} è¡ŒæœªçŸ¥è¯­éŸ³: ${item.voice}`);
    }
  });
  
  if (errors.length > 0) {
    throw new Error('å‰§æœ¬éªŒè¯å¤±è´¥:\n' + errors.join('\n'));
  }
  
  console.log('âœ… å‰§æœ¬æ ¼å¼éªŒè¯é€šè¿‡');
}

function generateFileHash(voice, line) {
  const content = `${voice}:${line}`;
  return createHash('md5').update(content, 'utf8').digest('hex').substring(0, 8);
}

async function generateAudioSegment(item, index, options, outputDir) {
  if (item.voice === 'sound_effect') {
    console.log(`â­ï¸  è·³è¿‡éŸ³æ•ˆ ${index + 1}: ${item.line.slice(0, 30)}...`);
    return null;
  }
  
  const voice = VOICE_MAPPING[item.voice];
  const fileHash = generateFileHash(item.voice, item.line);
  const filename = `segment_${String(index + 1).padStart(3, '0')}_${item.character}-${fileHash}.mp3`;
  const outputPath = path.join(outputDir, filename);
  
  // Check if file already exists
  if (fs.existsSync(outputPath)) {
    console.log(`â­ï¸  è·³è¿‡å·²å­˜åœ¨ ${index + 1}/${item.character}: ${item.line.slice(0, 50)}...`);
    return outputPath;
  }
  
  const ttsOptions = {
    voice: voice,
    output: outputPath,
    rate: options.rate,
    pitch: '0%',
    key: options.key,
    region: options.region,
    text: item.line,
    file: null,
    play: false
  };
  
  try {
    console.log(`ğŸ¤ ç”Ÿæˆ ${index + 1}/${item.character}: ${item.line.slice(0, 50)}...`);
    await synthesizeSpeech(ttsOptions);
    return outputPath;
  } catch (error) {
    console.error(`âŒ ç”Ÿæˆå¤±è´¥ ${index + 1}: ${error.message}`);
    return null;
  }
}

function createSilence(duration, outputPath) {
  return new Promise((resolve, reject) => {
    // Generate silence using ffmpeg
    const command = `ffmpeg -f lavfi -i anullsrc=channel_layout=mono:sample_rate=16000 -t ${duration} -acodec mp3 -y "${outputPath}"`;
    
    exec(command, (error) => {
      if (error) {
        reject(new Error(`ç”Ÿæˆé™éŸ³å¤±è´¥: ${error.message}`));
      } else {
        resolve(outputPath);
      }
    });
  });
}

function combineAudioFiles(audioFiles, outputPath, pauseDuration) {
  return new Promise((resolve, reject) => {
    console.log('ğŸ”— åˆå¹¶éŸ³é¢‘æ–‡ä»¶...');
    
    // Create a temporary file list for ffmpeg
    const fileListPath = path.join(path.dirname(outputPath), 'filelist.txt');
    const silencePath = path.join(path.dirname(outputPath), 'silence.mp3');
    
    // Generate silence file
    createSilence(pauseDuration, silencePath)
      .then(() => {
        // Create file list with silence between segments
        const fileList = [];
        audioFiles.forEach((file, index) => {
          if (file) {
            fileList.push(`file '${path.resolve(file)}'`);
            if (index < audioFiles.length - 1) {
              fileList.push(`file '${path.resolve(silencePath)}'`);
            }
          }
        });
        
        fs.writeFileSync(fileListPath, fileList.join('\n'));
        
        // Use ffmpeg to concatenate files
        const command = `ffmpeg -f concat -safe 0 -i "${fileListPath}" -c copy -y "${outputPath}"`;
        
        exec(command, (error) => {
          // Clean up temporary files
          try {
            fs.unlinkSync(fileListPath);
            fs.unlinkSync(silencePath);
          } catch {
            console.warn('âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥');
          }
          
          if (error) {
            reject(new Error(`åˆå¹¶éŸ³é¢‘å¤±è´¥: ${error.message}`));
          } else {
            console.log('âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ');
            resolve(outputPath);
          }
        });
      })
      .catch(reject);
  });
}

async function generateNarration(options) {
  if (!options.key) {
    throw new Error('âŒ Azure Speech APIå¯†é’¥æœªè®¾ç½®ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ SPEECH_KEY æˆ–ä½¿ç”¨ -k å‚æ•°');
  }
  
  if (!options.scriptFile || !options.outputDir) {
    throw new Error('âŒ è¯·æŒ‡å®šå‰§æœ¬æ–‡ä»¶å’Œè¾“å‡ºç›®å½•');
  }
  
  // Load and validate script
  const script = loadScript(options.scriptFile);
  validateScript(script);
  
  // Ensure output directory exists
  ensureDirectoryExists(options.outputDir);
  
  // Generate audio segments
  console.log('\nğŸ­ å¼€å§‹ç”Ÿæˆè¯­éŸ³ç‰‡æ®µ...');
  const audioFiles = [];
  
  for (let i = 0; i < script.length; i++) {
    const audioPath = await generateAudioSegment(script[i], i, options, options.outputDir);
    audioFiles.push(audioPath);
    
    // Add small delay between requests to avoid rate limiting
    if (i < script.length - 1) {
      await new Promise(resolve => setTimeout(resolve, 500));
    }
  }
  
  // Count successful generations and skipped files
  const successfulFiles = audioFiles.filter(file => file !== null);
  const totalLines = script.length;
  const soundEffectCount = script.filter(item => item.voice === 'sound_effect').length;
  const generatedCount = successfulFiles.length;
  const skippedExistingCount = script.filter((item, index) => {
    if (item.voice === 'sound_effect') return false;
    const fileHash = generateFileHash(item.voice, item.line);
    const filename = `segment_${String(index + 1).padStart(3, '0')}_${item.character}-${fileHash}.mp3`;
    const outputPath = path.join(options.outputDir, filename);
    return fs.existsSync(outputPath);
  }).length;
  
  console.log(`\nğŸ“Š ç”Ÿæˆç»Ÿè®¡:`);
  console.log(`ğŸ“ æ€»è¡Œæ•°: ${totalLines}`);
  console.log(`âœ… éŸ³é¢‘æ–‡ä»¶: ${generatedCount} ä¸ª`);
  console.log(`â­ï¸  è·³è¿‡éŸ³æ•ˆ: ${soundEffectCount} ä¸ª`);
  if (skippedExistingCount > 0) {
    console.log(`ğŸ”„ è·³è¿‡å·²å­˜åœ¨: ${skippedExistingCount} ä¸ª`);
  }
  
  // Combine audio files if requested
  if (options.combine && successfulFiles.length > 0) {
    const scriptName = path.basename(options.scriptFile, '.json');
    const combinedPath = path.join(options.outputDir, `${scriptName}_complete.mp3`);
    
    try {
      await combineAudioFiles(audioFiles, combinedPath, options.pause);
      console.log(`ğŸµ å®Œæ•´éŸ³é¢‘: ${combinedPath}`);
      
      // Get file size
      const stats = fs.statSync(combinedPath);
      const fileSizeInMB = (stats.size / 1024 / 1024).toFixed(2);
      console.log(`ğŸ“Š æ–‡ä»¶å¤§å°: ${fileSizeInMB} MB`);
    } catch (error) {
      console.error(`âŒ åˆå¹¶å¤±è´¥: ${error.message}`);
      console.log('ğŸ’¡ æç¤º: è¯·ç¡®ä¿å·²å®‰è£… ffmpeg');
    }
  }
  
  console.log('\nğŸ‰ è¯­éŸ³ç”Ÿæˆå®Œæˆ!');
}

// Main execution
async function main() {
  try {
    const options = parseArguments();
    
    if (process.argv.length < 4) {
      showUsage();
      process.exit(1);
    }
    
    await generateNarration(options);
  } catch (error) {
    console.error(error.message);
    process.exit(1);
  }
}

// Run if called directly
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}

export { generateNarration, VOICE_MAPPING }; 